# This is a GitHub Actions workflow file.
# It defines a job that will automatically run your Python scraper on a schedule.

name: Run Attendance Scraper

on:
  # This allows you to run the workflow manually from the Actions tab on GitHub.
  workflow_dispatch:
  
  # This schedule is now set to run the scraper every 30 minutes.
  schedule:
    - cron: '*/30 * * * *'

jobs:
  scrape:
    # The type of runner that the job will run on.
    runs-on: ubuntu-latest

    steps:
      # Step 1: Checks out your repository under $GITHUB_WORKSPACE, so your job can access it.
      - name: Check out repository
        uses: actions/checkout@v3

      # Step 2: Sets up a Python environment for your script.
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11' # You can specify a different version if needed.

      # Step 3: Install Python libraries.
      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
      
      # Step 4: Install Playwright browsers.
      - name: Install Playwright Browsers
        run: python -m playwright install --with-deps
      
      # Step 5: This is the main step. It runs your scraper.py script.
      # It uses environment variables to securely pass your Supabase credentials.
      - name: Run the scraper
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
        run: python scraper.py
